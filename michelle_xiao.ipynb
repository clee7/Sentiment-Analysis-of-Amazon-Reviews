{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Jenny branch\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "BORDER = \"----------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifyWithNeuralNetwork(X_train, Y_train, X_test):\n",
    "    \"\"\"\n",
    "    Function takes training and testing data, and fits using our neural network implementation\n",
    "    \n",
    "    Inputs:\n",
    "        X_train: The training data\n",
    "        Y_train: The training data labels\n",
    "        X_test:  The testing data\n",
    "        \n",
    "    Outputs:\n",
    "        prediction: a nparray with shape (X_test.shape[0], ) containing the predicted labels our model generated\n",
    "    \"\"\"\n",
    "    print('\\n{}\\nNEURAL NETWORK\\n{}\\n'.format(BORDER, BORDER))\n",
    "\n",
    "    # Converting Y values to one hot vector\n",
    "    num_classes = 2\n",
    "    Y_train = keras.utils.to_categorical(Y_train, num_classes=num_classes)\n",
    "    \n",
    "    # Input size\n",
    "    n_train = X_train.shape[0]\n",
    "    n_words = X_train.shape[1]\n",
    "    n_test = Y_train.shape[0]\n",
    "    \n",
    "    # Layer set up.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_shape=(n_words,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Dense(100, input_shape=(n_words,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Dense(50, input_shape=(n_words,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    ## Printing a summary of the layers and weights in your model\n",
    "    model.summary()\n",
    "\n",
    "    ## In the line below we have specified the loss function as 'mse' (Mean Squared Error) because in the above code we did not one-hot encode the labels.\n",
    "    ## In your implementation, since you are one-hot encoding the labels, you should use 'categorical_crossentropy' as your loss.\n",
    "    ## You will likely have the best results with RMS prop or Adam as your optimizer.  In the line below we use Adadelta\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='RMSprop', metrics=['accuracy'])\n",
    "\n",
    "    fit = model.fit(X_train, Y_train, batch_size=128, epochs=10, verbose=1)\n",
    "    \n",
    "    ## Printing the accuracy of our model, according to the loss function specified in model.compile above\n",
    "    score = model.evaluate(X_train, Y_train, verbose=0)\n",
    "    print('Training score:', score[0])\n",
    "    print('Training accuracy:', score[1])\n",
    "\n",
    "    prediction = model.predict(X_test, verbose=1)\n",
    "\n",
    "    zeros = prediction[:, 0]\n",
    "    ones  = prediction[:, 1]\n",
    "\n",
    "    prediction = (zeros < ones).astype(int)\n",
    "\n",
    "    return model, prediction, score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifyWithConvolutionNetwork(X_train, Y_train, X_test):\n",
    "    \"\"\"\n",
    "    Function takes training and testing data, and fits using our neural network implementation\n",
    "    \n",
    "    Inputs:\n",
    "        X_train: The training data\n",
    "        Y_train: The training data labels\n",
    "        X_test:  The testing data\n",
    "        \n",
    "    Outputs:\n",
    "        prediction: a nparray with shape (X_test.shape[0], ) containing the predicted labels our model generated\n",
    "    \"\"\"\n",
    "    print('\\n{}\\nNEURAL NETWORK\\n{}\\n'.format(BORDER, BORDER))\n",
    "\n",
    "    # Converting Y values to one hot vector\n",
    "    num_classes = 2\n",
    "    Y_train = keras.utils.to_categorical(Y_train, num_classes=num_classes)\n",
    "    \n",
    "    # Input size\n",
    "    n_train = X_train.shape[0]\n",
    "    n_words = X_train.shape[1]\n",
    "    n_test = Y_train.shape[0]\n",
    "    \n",
    "    \n",
    "    # For 1D Convolution, change dimension of input \n",
    "    X_train = np.expand_dims(X_train, axis=2)\n",
    "    X_test = np.expand_dims(X_test, axis=2)\n",
    "    \n",
    "        \n",
    "    ## Create your own model here given the constraints in the problem\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(5, 3, padding=\"same\", input_shape=(n_words, 1, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv1D(5, 2, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    ## Once you one-hot encode the data labels, the line below should be predicting probabilities of each of the 2 classes\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    ## Printing a summary of the layers and weights in your model\n",
    "    model.summary()\n",
    "\n",
    "    ## In the line below we have specified the loss function as 'mse' (Mean Squared Error) because in the above code we did not one-hot encode the labels.\n",
    "    ## In your implementation, since you are one-hot encoding the labels, you should use 'categorical_crossentropy' as your loss.\n",
    "    ## You will likely have the best results with RMS prop or Adam as your optimizer.  In the line below we use Adadelta\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='RMSprop', metrics=['accuracy'])\n",
    "\n",
    "    fit = model.fit(X_train, Y_train, batch_size=128, epochs=10, verbose=1)\n",
    "    \n",
    "    ## Printing the accuracy of our model, according to the loss function specified in model.compile above\n",
    "    score = model.evaluate(X_train, Y_train, verbose=0)\n",
    "    print('Training score:', score[0])\n",
    "    print('Training accuracy:', score[1])\n",
    "\n",
    "    prediction = model.predict(X_test, verbose=1)\n",
    "\n",
    "    zeros = prediction[:, 0]\n",
    "    ones  = prediction[:, 1]\n",
    "\n",
    "    prediction = (zeros < ones).astype(int)\n",
    "\n",
    "    return model, prediction, score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifyWithLogisticRegression(X_train, Y_train, X_test):\n",
    "    \"\"\"\n",
    "    Function takes training and testing data, and fits using logistic regression\n",
    "    \n",
    "    Inputs:\n",
    "        X_train: The training data\n",
    "        Y_train: The training data labels\n",
    "        X_test:  The testing data\n",
    "        \n",
    "    Outputs:\n",
    "        prediction: a nparray with shape (X_test.shape[0], ) containing the predicted labels our model generated\n",
    "    \"\"\"\n",
    "    \n",
    "    print('\\n{}\\nLOGISTIC REGRESSION\\n{}\\n'.format(BORDER, BORDER))\n",
    "    \n",
    "    model = linear_model.LogisticRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = model.predict(X_train)\n",
    "    \n",
    "    correctlyClassified = (Y_pred == Y_train).astype(int);\n",
    "    accuracy = np.sum(correctlyClassified) / correctlyClassified.shape[0]\n",
    "    \n",
    "    print('Training accuracy: ', accuracy)\n",
    "    \n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    return model, prediction, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidation(X_train, Y_train, X_test):\n",
    "    kf = KFold(n_splits = 5)\n",
    "    inds = [ind for ind in kf.split(X_train, Y_train)]\n",
    "        \n",
    "    total_train_acc = []\n",
    "    total_val_acc = []\n",
    "    \n",
    "     # Converting Y values to one hot vector\n",
    "    num_classes = 2\n",
    "    Y = keras.utils.to_categorical(Y_train, num_classes=num_classes)\n",
    "    \n",
    "    \n",
    "    # For 1D Convolution, change dimension of input \n",
    "    X = np.expand_dims(X_train, axis=2)\n",
    "    \n",
    "    \n",
    "    # perform 5-fold validation\n",
    "    for i in range(0,5):\n",
    "        traini, vali = inds[i]\n",
    "        model, prediction, accuracy = ClassifyWithConvolutionNetwork(X_train[traini], Y_train[traini],X_test)\n",
    "        \n",
    "                \n",
    "        # Compute accuracy.\n",
    "        val_acc = model.evaluate(X[vali], Y[vali], verbose=1)\n",
    "            \n",
    "        total_train_acc = np.append(total_train_acc, accuracy)\n",
    "        total_val_acc = np.append(total_val_acc, val_acc[1])\n",
    "\n",
    "    print(\"training accuracy\", total_train_acc)\n",
    "    print(\"val accuracy\", total_val_acc)\n",
    "    print(\"average training accuracy\", np.sum(total_train_acc) / 5.)\n",
    "    print(\"average val accuracy\", np.sum(total_val_acc) / 5.)\n",
    "    \n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads training dataset\n",
    "training = load_data('data/training_data.txt', 1)\n",
    "X_train = training[:, 1:]\n",
    "Y_train = training[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads testing dataset\n",
    "# There is no label for testing set \n",
    "X_test = load_data('data/test_data.txt', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------\n",
      "NEURAL NETWORK\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 1000, 5)           20        \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1000, 5)           20        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 1000, 5)           55        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 500, 5)            0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 500, 5)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               250100    \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 250,397\n",
      "Trainable params: 250,387\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 14s 856us/step - loss: 0.5984 - acc: 0.7039\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 11s 707us/step - loss: 0.4324 - acc: 0.8034\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 12s 758us/step - loss: 0.3775 - acc: 0.8319\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 11s 695us/step - loss: 0.3256 - acc: 0.8624\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 11s 708us/step - loss: 0.2814 - acc: 0.8834\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 13s 815us/step - loss: 0.2375 - acc: 0.9036\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 12s 734us/step - loss: 0.1976 - acc: 0.9211\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 11s 709us/step - loss: 0.1703 - acc: 0.9352\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 11s 686us/step - loss: 0.1457 - acc: 0.9439\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 15s 966us/step - loss: 0.1256 - acc: 0.9540\n",
      "Training score: 0.04874499912001193\n",
      "Training accuracy: 0.9904375\n",
      "10000/10000 [==============================] - 4s 409us/step\n",
      "4000/4000 [==============================] - 1s 336us/step\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "NEURAL NETWORK\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_17 (Conv1D)           (None, 1000, 5)           20        \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1000, 5)           20        \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1000, 5)           55        \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 500, 5)            0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 500, 5)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               250100    \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 250,397\n",
      "Trainable params: 250,387\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 16s 997us/step - loss: 0.5413 - acc: 0.7343\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 11s 696us/step - loss: 0.4356 - acc: 0.8011\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 11s 693us/step - loss: 0.3683 - acc: 0.8379\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 11s 694us/step - loss: 0.3049 - acc: 0.8689\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 11s 700us/step - loss: 0.2509 - acc: 0.8976\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 12s 767us/step - loss: 0.1950 - acc: 0.9236\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 11s 694us/step - loss: 0.1568 - acc: 0.9402\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 11s 708us/step - loss: 0.1323 - acc: 0.9494\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 11s 710us/step - loss: 0.1061 - acc: 0.9596\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 12s 728us/step - loss: 0.0899 - acc: 0.9677\n",
      "Training score: 0.030107463819906116\n",
      "Training accuracy: 0.996625\n",
      "10000/10000 [==============================] - 3s 326us/step\n",
      "4000/4000 [==============================] - 1s 307us/step\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "NEURAL NETWORK\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_19 (Conv1D)           (None, 1000, 5)           20        \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1000, 5)           20        \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 1000, 5)           55        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 500, 5)            0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 500, 5)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               250100    \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 250,397\n",
      "Trainable params: 250,387\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 12s 749us/step - loss: 0.5592 - acc: 0.7401\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 11s 699us/step - loss: 0.3946 - acc: 0.8250\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 12s 751us/step - loss: 0.3351 - acc: 0.8549\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 11s 701us/step - loss: 0.2900 - acc: 0.8789\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 11s 705us/step - loss: 0.2384 - acc: 0.9019\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 11s 694us/step - loss: 0.2000 - acc: 0.9213\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 11s 696us/step - loss: 0.1615 - acc: 0.9368\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 11s 716us/step - loss: 0.1361 - acc: 0.9476\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 11s 716us/step - loss: 0.1157 - acc: 0.9579\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 11s 703us/step - loss: 0.1047 - acc: 0.9611\n",
      "Training score: 0.028852741393260658\n",
      "Training accuracy: 0.9958125\n",
      "10000/10000 [==============================] - 3s 333us/step\n",
      "4000/4000 [==============================] - 1s 307us/step\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "NEURAL NETWORK\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 1000, 5)           20        \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1000, 5)           20        \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 1000, 5)           55        \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 500, 5)            0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 500, 5)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               250100    \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 250,397\n",
      "Trainable params: 250,387\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 12s 759us/step - loss: 0.5487 - acc: 0.7219\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 11s 703us/step - loss: 0.4293 - acc: 0.8059\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 11s 698us/step - loss: 0.3737 - acc: 0.8317\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 13s 784us/step - loss: 0.3389 - acc: 0.8507\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 12s 779us/step - loss: 0.3011 - acc: 0.8761\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 13s 801us/step - loss: 0.2682 - acc: 0.8896\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 12s 729us/step - loss: 0.2306 - acc: 0.9083\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 11s 708us/step - loss: 0.2032 - acc: 0.9188\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 11s 700us/step - loss: 0.1749 - acc: 0.9311\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 11s 704us/step - loss: 0.1476 - acc: 0.9431\n",
      "Training score: 0.05638047376275063\n",
      "Training accuracy: 0.9899375\n",
      "10000/10000 [==============================] - 4s 440us/step\n",
      "4000/4000 [==============================] - 2s 440us/step\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "NEURAL NETWORK\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_23 (Conv1D)           (None, 1000, 5)           20        \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1000, 5)           20        \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1000, 5)           55        \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 500, 5)            0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 500, 5)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               250100    \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 250,397\n",
      "Trainable params: 250,387\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 12s 766us/step - loss: 0.5578 - acc: 0.7302\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 11s 703us/step - loss: 0.4089 - acc: 0.8156\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 11s 703us/step - loss: 0.3449 - acc: 0.8513\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 11s 704us/step - loss: 0.2897 - acc: 0.8775\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 11s 718us/step - loss: 0.2430 - acc: 0.9012\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 12s 743us/step - loss: 0.1982 - acc: 0.9219\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 14s 853us/step - loss: 0.1700 - acc: 0.9339\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 11s 700us/step - loss: 0.1409 - acc: 0.9453\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 14s 902us/step - loss: 0.1206 - acc: 0.9560\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 14s 861us/step - loss: 0.1003 - acc: 0.9636\n",
      "Training score: 0.04801295974291861\n",
      "Training accuracy: 0.99025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 372us/step\n",
      "4000/4000 [==============================] - 1s 315us/step\n",
      "training accuracy [0.9904375 0.996625  0.9958125 0.9899375 0.99025  ]\n",
      "val accuracy [0.818   0.80325 0.80525 0.817   0.80775]\n",
      "average training accuracy 0.9926124999999999\n",
      "average val accuracy 0.8102499999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Validation \n",
    "CrossValidation(X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, prediction, accuracy = ClassifyWithNeuralNetwork(X_train, Y_train, X_test)\n",
    "model, prediction, accuracy  = ClassifyWithConvolutionNetwork(X_train, Y_train, X_test)\n",
    "model, prediction, accuracy  = ClassifyWithLogisticRegression(X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)\n",
    "print(\"prediction shape is: {}\".format(prediction.shape))\n",
    "\n",
    "output = \"Id,Prediction\\n\"\n",
    "for i in range(prediction.shape[0]):\n",
    "    output = output + (\"{0},{1}\\n\".format(i + 1, prediction[i]))\n",
    "\n",
    "file = open('predictions.csv','w') \n",
    "file.write(output)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
