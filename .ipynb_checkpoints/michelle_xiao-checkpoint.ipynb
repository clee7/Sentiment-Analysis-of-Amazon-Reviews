{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5b70ac5495d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Jenny branch\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads training dataset\n",
    "training = load_data('data/training_data.txt', 1)\n",
    "X_train = training[:, 1:]\n",
    "Y_train = training[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads testing dataset\n",
    "# There is no label for testing set \n",
    "X_test = load_data('data/test_data.txt', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Y values to one hot vector\n",
    "num_classes = 2\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input size\n",
    "n_train = X_train.shape[0]\n",
    "n_words = X_train.shape[1]\n",
    "n_test = Y_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 1D Convolution, change dimension of input \n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation\n",
    "X_val = X_train[:4000,:]\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (20000, 1000, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 1000, 5)           20        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1000, 5)           20        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 1000, 5)           55        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1000, 5)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 500, 5)            0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 500, 5)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               250100    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 250,397\n",
      "Trainable params: 250,387\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.5490 - acc: 0.7376\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 18s 894us/step - loss: 0.4118 - acc: 0.8157\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.3582 - acc: 0.8451\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 18s 919us/step - loss: 0.3151 - acc: 0.8686\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 19s 964us/step - loss: 0.2722 - acc: 0.8869\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 18s 901us/step - loss: 0.2334 - acc: 0.9052\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 20s 978us/step - loss: 0.1990 - acc: 0.9212\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 20s 977us/step - loss: 0.1736 - acc: 0.9340\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.1490 - acc: 0.9422\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 19s 936us/step - loss: 0.1279 - acc: 0.9512\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train\", X_train.shape)\n",
    "## Create your own model here given the constraints in the problem\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(5, 3, padding=\"same\", input_shape=(n_words, 1, )))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv1D(5, 2, padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "## Once you one-hot encode the data labels, the line below should be predicting probabilities of each of the 2 classes\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "## Printing a summary of the layers and weights in your model\n",
    "model.summary()\n",
    "\n",
    "## In the line below we have specified the loss function as 'mse' (Mean Squared Error) because in the above code we did not one-hot encode the labels.\n",
    "## In your implementation, since you are one-hot encoding the labels, you should use 'categorical_crossentropy' as your loss.\n",
    "## You will likely have the best results with RMS prop or Adam as your optimizer.  In the line below we use Adadelta\n",
    "model.compile(loss='categorical_crossentropy',optimizer='RMSprop', metrics=['accuracy'])\n",
    "\n",
    "fit = model.fit(X_train, Y_train, batch_size=128, epochs=10,\n",
    "    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 7s 346us/step\n",
      "Test score: 0.02730713826008141\n",
      "Test accuracy: 0.99545\n"
     ]
    }
   ],
   "source": [
    "## Printing the accuracy of our model, according to the loss function specified in model.compile above\n",
    "score = model.evaluate(X_train, Y_train, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 353us/step\n",
      "[[2.2222267e-01 7.7777737e-01]\n",
      " [1.1466056e-03 9.9885345e-01]\n",
      " [9.5059520e-01 4.9404785e-02]\n",
      " ...\n",
      " [9.9946755e-01 5.3248100e-04]\n",
      " [2.2229988e-02 9.7777003e-01]\n",
      " [9.8719287e-01 1.2807099e-02]]\n",
      "[1 1 0 ... 0 1 0]\n",
      "prediction shape is: (10000,)\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test, verbose=1)\n",
    "print(prediction)\n",
    "\n",
    "zeros = prediction[:, 0]\n",
    "ones  = prediction[:, 1]\n",
    "\n",
    "prediction = (zeros < ones).astype(int)\n",
    "\n",
    "print(prediction)\n",
    "print(\"prediction shape is: {}\".format(prediction.shape))\n",
    "\n",
    "output = \"Id,Prediction\\n\"\n",
    "for i in range(prediction.shape[0]):\n",
    "    output = output + (\"{0},{1}\\n\".format(i + 1, prediction[i]))\n",
    "\n",
    "file = open('predictions.csv','w') \n",
    "file.write(output)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
