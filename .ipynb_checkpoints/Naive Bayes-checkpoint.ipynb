{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Jenny branch\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "from sklearn import linear_model, ensemble, tree, svm, naive_bayes\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BORDER = \"====================================================================================\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WritePredictionOut(modelName, prediction):\n",
    "    print(prediction)\n",
    "    print(\"prediction shape is: {}\".format(prediction.shape))\n",
    "\n",
    "    output = \"Id,Prediction\\n\"\n",
    "    for i in range(prediction.shape[0]):\n",
    "        output = output + (\"{0},{1}\\n\".format(i + 1, prediction[i].astype(int)))\n",
    "\n",
    "        \n",
    "    now = datetime.datetime.now();\n",
    "        \n",
    "    filename = \"{}_{}.{}.{}_{}.{}.{}_predictions.csv\".format(modelName, now.year, now.month, now.day, now.hour, now.minute, now.second)\n",
    "        \n",
    "    file = open(filename,'w') \n",
    "    file.write(output)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifyWithBernoulliNB(X_train, Y_train, X_test, alpha, verbose=0):\n",
    "    \"\"\"\n",
    "    Function takes training and testing data, and fits using logistic regression\n",
    "    \n",
    "    Inputs:\n",
    "        X_train: The training data\n",
    "        Y_train: The training data labels\n",
    "        X_test:  The testing data\n",
    "        \n",
    "    Outputs:\n",
    "        model: passes out the model we trained.\n",
    "        prediction: a nparray with shape (X_test.shape[0], ) containing the predicted labels our model generated\n",
    "        accuracy: training accuracy of model.\n",
    "    \"\"\"\n",
    "    \n",
    "    if (verbose == 1):\n",
    "        print('\\n{}\\nBernoulli Naive Bayes\\n{}\\n'.format(BORDER, BORDER))\n",
    "        \n",
    "    model = naive_bayes.BernoulliNB(alpha=alpha)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = model.predict(X_train)\n",
    "    \n",
    "    correctlyClassified = (Y_pred == Y_train).astype(int);\n",
    "    accuracy = np.sum(correctlyClassified) / correctlyClassified.shape[0]\n",
    "    \n",
    "    if (verbose == 1):\n",
    "        print('Training accuracy: ', accuracy)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    return model, prediction, accuracy\n",
    "\n",
    "def ClassifyWithMultinomialNB(X_train, Y_train, X_test, alpha, verbose=0):\n",
    "    \"\"\"\n",
    "    Function takes training and testing data, and fits using logistic regression\n",
    "    \n",
    "    Inputs:\n",
    "        X_train: The training data\n",
    "        Y_train: The training data labels\n",
    "        X_test:  The testing data\n",
    "        \n",
    "    Outputs:\n",
    "        model: passes out the model we trained.\n",
    "        prediction: a nparray with shape (X_test.shape[0], ) containing the predicted labels our model generated\n",
    "        accuracy: training accuracy of model.\n",
    "    \"\"\"\n",
    "    \n",
    "    if (verbose == 1):\n",
    "        print('\\n{}\\nMultinomial Naive Bayes\\n{}\\n'.format(BORDER, BORDER))\n",
    "        \n",
    "    model = naive_bayes.MultinomialNB(alpha=alpha)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = model.predict(X_train)\n",
    "    \n",
    "    correctlyClassified = (Y_pred == Y_train).astype(int);\n",
    "    accuracy = np.sum(correctlyClassified) / correctlyClassified.shape[0]\n",
    "    \n",
    "    if (verbose == 1):\n",
    "        print('Training accuracy: ', accuracy)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    return model, prediction, accuracy\n",
    "\n",
    "def ClassifyWithBaggedMultinomialNB(X_train, Y_train, X_test, alpha, verbose=0):\n",
    "    \"\"\"\n",
    "    Function takes training and testing data, and fits using logistic regression\n",
    "    \n",
    "    Inputs:\n",
    "        X_train: The training data\n",
    "        Y_train: The training data labels\n",
    "        X_test:  The testing data\n",
    "        \n",
    "    Outputs:\n",
    "        model: passes out the model we trained.\n",
    "        prediction: a nparray with shape (X_test.shape[0], ) containing the predicted labels our model generated\n",
    "        accuracy: training accuracy of model.\n",
    "    \"\"\"\n",
    "    \n",
    "    if (verbose == 1):\n",
    "        print('\\n{}\\nMultinomial Naive Bayes\\n{}\\n'.format(BORDER, BORDER))\n",
    "    base = naive_bayes.MultinomialNB(alpha=alpha)\n",
    "    \n",
    "    model = ensemble.BaggingClassifier(base_estimator=base, n_estimators=100, verbose=verbose)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = model.predict(X_train)\n",
    "    \n",
    "    correctlyClassified = (Y_pred == Y_train).astype(int);\n",
    "    accuracy = np.sum(correctlyClassified) / correctlyClassified.shape[0]\n",
    "    \n",
    "    if (verbose == 1):\n",
    "        print('Training accuracy: ', accuracy)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    return model, prediction, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidate(modelFunction, X_train, Y_train, X_test, alpha, nFold, verbose=0):\n",
    "    kf = KFold(n_splits = nFold)\n",
    "    inds = [ind for ind in kf.split(X_train, Y_train)]\n",
    "        \n",
    "    total_train_acc = []\n",
    "    total_val_acc = []\n",
    "    \n",
    "    \n",
    "    # perform 5-fold validation\n",
    "    for i in range(0,5):\n",
    "        traini, vali = inds[i]\n",
    "        model, prediction, accuracy = modelFunction(X_train[traini], Y_train[traini], X_test, alpha, verbose=verbose)\n",
    "        \n",
    "        # Compute accuracy.\n",
    "        val_acc = model.score(X_train[vali], Y_train[vali])\n",
    "            \n",
    "        total_train_acc = np.append(total_train_acc, accuracy)\n",
    "        total_val_acc = np.append(total_val_acc, val_acc)\n",
    "\n",
    "#     print(BORDER)\n",
    "#     print(\"CROSS VALIDATION: \" + modelFunction.__name__)\n",
    "#     print(BORDER)\n",
    "#     print(\"training accuracy\", total_train_acc)\n",
    "#     print(\"val accuracy\", total_val_acc)\n",
    "#     print(\"average training accuracy\", np.sum(total_train_acc) / float(nFold))\n",
    "#     print(\"average val accuracy\", np.sum(total_val_acc) / float(nFold))\n",
    "\n",
    "    accuracy = np.sum(total_val_acc) / float(nFold);\n",
    "#     print('{0} -- alpha = {1} -- accuracy = {2}'.format(modelFunction.__name__, alpha, accuracy))\n",
    "    \n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads training dataset\n",
    "training = load_data('data/training_data.txt', 1)\n",
    "X_train = training[:, 1:]\n",
    "Y_train = training[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads testing dataset\n",
    "# There is no label for testing set \n",
    "X_test = load_data('data/test_data.txt', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================\n",
      "Multinomial Naive Bayes\n",
      "====================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.8381875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================\n",
      "Multinomial Naive Bayes\n",
      "====================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.83775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================\n",
      "Multinomial Naive Bayes\n",
      "====================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.839375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================\n",
      "Multinomial Naive Bayes\n",
      "====================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.8399375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================\n",
      "Multinomial Naive Bayes\n",
      "====================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.839875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.8308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Using Validation\n",
    "numIterations = 100\n",
    "\n",
    "alphas = []\n",
    "bernoulliAccuracy = []\n",
    "multinomialAccuracy = []\n",
    "\n",
    "\n",
    "accuracy = CrossValidate(ClassifyWithBaggedMultinomialNB, X_train, Y_train, X_test, 0.01, 5, verbose=1);\n",
    "\n",
    "print (\"accuracy is {}\".format(accuracy));\n",
    "\n",
    "# for i in range(numIterations):\n",
    "#     alpha = (i + 1) * (1 / numIterations)\n",
    "#     alphas.append(alpha)\n",
    "    \n",
    "#     print(\"alpha = {}\".format(alpha))\n",
    "    \n",
    "#     bernoulliAccuracy.append(CrossValidate(ClassifyWithBernoulliNB, X_train, Y_train, X_test, alpha, 5, verbose=0))\n",
    "#     multinomialAccuracy.append(CrossValidate(ClassifyWithMultinomialNB, X_train, Y_train, X_test, alpha, 5, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jerry\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1db394786a0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1db39468908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1db38f7b710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bernoulliFig = plt.figure()\n",
    "plt.title(\"Bernoulli NB -- alpha vs accuracy\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "bernoulliAX1 = bernoulliFig.add_subplot(111)\n",
    "bernoulliAX1.plot(alphas, bernoulliAccuracy)\n",
    "\n",
    "\n",
    "multinomialFig = plt.figure()\n",
    "plt.title(\"Multinomial NB -- alpha vs accuracy\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "multinomialAX1 = multinomialFig.add_subplot(111)\n",
    "multinomialAX1.plot(alphas, multinomialAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.817, 0.817, 0.817, 0.81705, 0.81705, 0.8171000000000002, 0.8171000000000002, 0.8171000000000002, 0.81705, 0.81705, 0.817, 0.817, 0.817, 0.817, 0.817, 0.817, 0.817, 0.8169500000000001, 0.8169500000000001, 0.8169500000000001, 0.8169000000000001, 0.8169000000000001, 0.81685, 0.81685, 0.81685, 0.8169000000000001, 0.81685, 0.81685, 0.8169000000000001, 0.81685, 0.81685, 0.81685, 0.81685, 0.81685, 0.81685, 0.81685, 0.81685, 0.81685, 0.81685, 0.8168, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8168, 0.8167499999999999, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8166499999999999, 0.8167, 0.8167, 0.8167, 0.8167500000000001, 0.8168000000000001, 0.8168500000000002, 0.8168500000000002, 0.8169000000000001, 0.81695, 0.81695, 0.81695, 0.8169000000000001, 0.8169000000000001, 0.8169000000000001, 0.8169000000000001, 0.8169000000000001, 0.81695, 0.8169000000000001, 0.81685, 0.81685, 0.8168, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167, 0.8167, 0.8166500000000001, 0.8166, 0.81655]\n",
      "[0.817, 0.817, 0.817, 0.81705, 0.81705, 0.8171000000000002, 0.8171000000000002, 0.8171000000000002, 0.81705, 0.81705, 0.817, 0.817, 0.817, 0.817, 0.817, 0.817, 0.817, 0.8169500000000001, 0.8169500000000001, 0.8169500000000001, 0.8169000000000001, 0.8169000000000001, 0.81685, 0.81685, 0.81685, 0.8169000000000001, 0.81685, 0.81685, 0.8169000000000001, 0.81685, 0.81685, 0.81685, 0.81685, 0.81685, 0.81685, 0.81685, 0.81685, 0.81685, 0.81685, 0.8168, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8168, 0.8167499999999999, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8167, 0.8166499999999999, 0.8167, 0.8167, 0.8167, 0.8167500000000001, 0.8168000000000001, 0.8168500000000002, 0.8168500000000002, 0.8169000000000001, 0.81695, 0.81695, 0.81695, 0.8169000000000001, 0.8169000000000001, 0.8169000000000001, 0.8169000000000001, 0.8169000000000001, 0.81695, 0.8169000000000001, 0.81685, 0.81685, 0.8168, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167499999999999, 0.8167, 0.8167, 0.8166500000000001, 0.8166, 0.81655]\n"
     ]
    }
   ],
   "source": [
    "print(multinomialAccuracy)\n",
    "print(bernoulliAccuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 1. 0.]\n",
      "prediction shape is: (10000,)\n"
     ]
    }
   ],
   "source": [
    "model, prediction, accuracy = ClassifyWithMultinomialNB(X_train, Y_train, X_test, alpha=0.01, verbose=0)\n",
    "WritePredictionOut('MultinomialNB', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ClassifyWithNeuralNetwork() got multiple values for argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-02895feed1f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m \u001b[0mClassifyWithNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: ClassifyWithNeuralNetwork() got multiple values for argument 'verbose'"
     ]
    }
   ],
   "source": [
    "def CrossValidation_NeuralNetwork(X_train, Y_train, X_test, nFold, verbose=0):\n",
    "    kf = KFold(n_splits = nFold)\n",
    "    inds = [ind for ind in kf.split(X_train, Y_train)]\n",
    "        \n",
    "    total_train_acc = []\n",
    "    total_val_acc = []\n",
    "    \n",
    "     # Converting Y values to one hot vector\n",
    "    num_classes = 2\n",
    "    Y = keras.utils.to_categorical(Y_train, num_classes=num_classes)\n",
    "    \n",
    "    # perform 5-fold validation\n",
    "    for i in range(0,5):\n",
    "        traini, vali = inds[i]\n",
    "        model, prediction, accuracy = ClassifyWithNeuralNetwork(X_train[traini], Y_train[traini], X_test)\n",
    "        \n",
    "        # Compute accuracy.\n",
    "        val_acc = model.evaluate(X_train[vali], Y[vali], verbose=verbose)\n",
    "            \n",
    "        total_train_acc = np.append(total_train_acc, accuracy)\n",
    "        total_val_acc = np.append(total_val_acc, val_acc[1])\n",
    "\n",
    "    print(BORDER)\n",
    "    print(\"CROSS VALIDATION: ClassifyWithNeuralNetwork\")\n",
    "    print(BORDER)\n",
    "    print(\"training accuracy\", total_train_acc)\n",
    "    print(\"val accuracy\", total_val_acc)\n",
    "    print(\"average training accuracy\", np.sum(total_train_acc) / 5.)\n",
    "    print(\"average val accuracy\", np.sum(total_val_acc) / 5.)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def ClassifyWithNeuralNetwork(X_train, Y_train, X_test, verbose=0):\n",
    "    \"\"\"\n",
    "   Function takes training and testing data, and fits using our neural network implementation\n",
    "   \n",
    "   Inputs:\n",
    "       X_train: The training data\n",
    "       Y_train: The training data labels\n",
    "       X_test:  The testing data\n",
    "       \n",
    "   Outputs:\n",
    "       model: passes out the model we trained.\n",
    "       prediction: a nparray with shape (X_test.shape[0], ) containing the predicted labels our model generated\n",
    "       accuracy: training accuracy of model.\n",
    "   \"\"\"\n",
    "    if (verbose == 1):\n",
    "        print('\\n{}\\nNEURAL NETWORK\\n{}\\n'.format(BORDER, BORDER))\n",
    " \n",
    "    # Converting Y values to one hot vector\n",
    "    num_classes = 2\n",
    "    Y_train = keras.utils.to_categorical(Y_train, num_classes=num_classes)\n",
    "   \n",
    "    # Input size\n",
    "    n_train = X_train.shape[0]\n",
    "    n_words = X_train.shape[1]\n",
    "    n_test = Y_train.shape[0]\n",
    "   \n",
    "    # Layer set up.\n",
    "    model = Sequential()\n",
    "   \n",
    "    model.add(Dense(1024, input_shape=(n_words, )))\n",
    "    model.add(Activation('relu'))\n",
    " \n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    " \n",
    "    ## Printing a summary of the layers and weights in your model\n",
    "    if (verbose == 1):\n",
    "        model.summary()\n",
    " \n",
    "    ## In the line below we have specified the loss function as 'mse' (Mean Squared Error) because in the above code we did not one-hot encode the labels.\n",
    "    ## In your implementation, since you are one-hot encoding the labels, you should use 'categorical_crossentropy' as your loss.\n",
    "    ## You will likely have the best results with RMS prop or Adam as your optimizer.  In the line below we use Adadelta\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    " \n",
    "    fit = model.fit(X_train, Y_train, batch_size=512, epochs=2, verbose=verbose, validation_split=0.1)\n",
    "   \n",
    "    ## Printing the accuracy of our model, according to the loss function specified in model.compile above\n",
    "    score = model.evaluate(X_train, Y_train, verbose=0)\n",
    "    if (verbose == 1):\n",
    "        print('Training score:', score[0])\n",
    "        print('Training accuracy:', score[1])\n",
    " \n",
    "    prediction = model.predict(X_test, verbose=verbose)\n",
    " \n",
    "    zeros = prediction[:, 0]\n",
    "    ones  = prediction[:, 1]\n",
    " \n",
    "    prediction = (zeros < ones).astype(int)\n",
    " \n",
    "    return model, prediction, score[1]\n",
    "\n",
    "CrossValidation_NeuralNetwork(X_train, Y_train, X_test, 5, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
