{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Jerry branch\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "from sklearn import linear_model, ensemble, tree, svm, naive_bayes, model_selection\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    " m\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BORDER = \"====================================================================================\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WritePredictionOut(modelName, prediction):\n",
    "    print(prediction)\n",
    "    print(\"prediction shape is: {}\".format(prediction.shape))\n",
    "\n",
    "    output = \"Id,Prediction\\n\"\n",
    "    for i in range(prediction.shape[0]):\n",
    "        output = output + (\"{0},{1}\\n\".format(i + 1, prediction[i].astype(int)))\n",
    "\n",
    "        \n",
    "    now = datetime.datetime.now();\n",
    "        \n",
    "    filename = \"{}_{}.{}.{}_{}.{}.{}_predictions.csv\".format(modelName, now.year, now.month, now.day, now.hour, now.minute, now.second)\n",
    "        \n",
    "    file = open(filename,'w') \n",
    "    file.write(output)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifyWithSVM(X_train, Y_train, X_test, verbose=0):\n",
    "    \"\"\"\n",
    "    Function takes training and testing data, and fits using logistic regression\n",
    "    \n",
    "    Inputs:\n",
    "        X_train: The training data\n",
    "        Y_train: The training data labels\n",
    "        X_test:  The testing data\n",
    "        \n",
    "    Outputs:\n",
    "        model: passes out the model we trained.\n",
    "        prediction: a nparray with shape (X_test.shape[0], ) containing the predicted labels our model generated\n",
    "        accuracy: training accuracy of model.\n",
    "    \"\"\"\n",
    "    \n",
    "    if (verbose == 1):\n",
    "        print('\\n{}\\nSVM\\n{}\\n'.format(BORDER, BORDER))\n",
    "        \n",
    "    model = svm.LinearSVC(C=0.03, loss='hinge', verbose=verbose)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    accuracy = model.score(X_train, Y_train)\n",
    "    \n",
    "    if (verbose == 1):\n",
    "        print('Training accuracy: ', accuracy)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    return model, prediction, accuracy\n",
    "\n",
    "def CrossValidate(X_train, Y_train, X_test, nFold, verbose=0):\n",
    "    kf = KFold(n_splits = nFold)\n",
    "    inds = [ind for ind in kf.split(X_train, Y_train)]\n",
    "        \n",
    "    total_train_acc = []\n",
    "    total_val_acc = []\n",
    "    \n",
    "    \n",
    "    # perform 5-fold validation\n",
    "    for i in range(0,5):\n",
    "        traini, vali = inds[i]\n",
    "        model, prediction, accuracy = ClassifyWithSVM(X_train[traini], Y_train[traini], X_test, verbose=verbose)\n",
    "        \n",
    "        # Compute accuracy.\n",
    "        val_acc = model.score(X_train[vali], Y_train[vali])\n",
    "            \n",
    "        total_train_acc = np.append(total_train_acc, accuracy)\n",
    "        total_val_acc = np.append(total_val_acc, val_acc)\n",
    "\n",
    "\n",
    "    accuracy = np.sum(total_val_acc) / float(nFold);\n",
    "    \n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads training dataset\n",
    "training = load_data('data/training_data.txt', 1)\n",
    "X_train = training[:, 1:]\n",
    "Y_train = training[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads testing dataset\n",
    "# There is no label for testing set \n",
    "X_test = load_data('data/test_data.txt', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'loss': ('hinge', 'squared_hinge'), 'C': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42...0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numCs = 100\n",
    "Cs = []\n",
    "for i in range(numCs):\n",
    "    Cs.append((i + 1) / numCs)\n",
    "\n",
    "svc = svm.LinearSVC()\n",
    "# parameters = {'penalty':('l1', 'l2'), 'loss':('hinge', 'squared_hinge'), 'C':Cs}\n",
    "parameters = {'loss':('hinge', 'squared_hinge'), 'C':Cs}\n",
    "\n",
    "\n",
    "clf = model_selection.GridSearchCV(svc, parameters, verbose=1)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87535"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.03, 'loss': 'hinge'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================\n",
      "SVM\n",
      "====================================================================================\n",
      "\n",
      "[LibLinear]Training accuracy:  0.873625\n",
      "\n",
      "====================================================================================\n",
      "SVM\n",
      "====================================================================================\n",
      "\n",
      "[LibLinear]Training accuracy:  0.8748125\n",
      "\n",
      "====================================================================================\n",
      "SVM\n",
      "====================================================================================\n",
      "\n",
      "[LibLinear]Training accuracy:  0.8779375\n",
      "\n",
      "====================================================================================\n",
      "SVM\n",
      "====================================================================================\n",
      "\n",
      "[LibLinear]Training accuracy:  0.878\n",
      "\n",
      "====================================================================================\n",
      "SVM\n",
      "====================================================================================\n",
      "\n",
      "[LibLinear]Training accuracy:  0.8746875\n",
      "Accuracy is 0.84825\n"
     ]
    }
   ],
   "source": [
    "accuracy = CrossValidate(X_train, Y_train, X_test, 5, verbose = 1);\n",
    "print(\"Accuracy is {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. ... 0. 1. 0.]\n",
      "prediction shape is: (10000,)\n"
     ]
    }
   ],
   "source": [
    "WritePredictionOut(\"SVC_C0.03_HingeLoss\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NuSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n"
     ]
    }
   ],
   "source": [
    "numNus = 100\n",
    "Nus = []\n",
    "for i in range(numNus):\n",
    "    Nus.append((i + 1) / numNus)\n",
    "    \n",
    "    \n",
    "svc = svm.NuSVC()\n",
    "# parameters = {'penalty':('l1', 'l2'), 'loss':('hinge', 'squared_hinge'), 'C':Cs}\n",
    "parameters = {'kernel':('rbf', 'linear', 'poly', 'sigmoid'), 'nu':Nus}\n",
    " \n",
    "\n",
    "clf = model_selection.GridSearchCV(svc, parameters, verbose=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
